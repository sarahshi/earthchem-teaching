{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Mineral-Machine Learning (MIN-ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Created on June 30, 2023 // @author: Sarah Shi \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Introduction\n",
    "\n",
    "#### Motivations for Applying Machine Learning to Mineral Data \n",
    "\n",
    "Explorations of mineral compositions aiming to reveal complex magmatic processes in melts have proliferated with the growing accessibility of geochemical datasets through databases including PetDB, LEPR/TraceDs, and GEOROC and of computational methods [1]. The generation and continuous quality assurance of mineral data in these databases requires significant human intervention and individual post-processing. One major problem is that minerals may be misclassified (i.e., a compiled dataset of clinopyroxenes may contain some amphiboles), and compilations may contain poor-quality electron microprobe (EPMA) analyses (with low totals, low cation sums, or poor correspondence to the theoretical stoichiometry of a mineral phase). At the moment, individual studies compiling geochemical datasets for specific tectonic settings [2] or calibrating thermobarometers based on mineral-melt equilibrium [3] tend to apply their own filters. With a push for a more consistent approach, we create a new open-source Python package called MIN-ML (MINeral classification using Machine Learning) for classifying common igneous minerals based on oxide data collected by EPMA, with functions for calculating stoichiometries and crystallographic sites based on this classification. Utilizing this package allows for the identification of misclassified mineral phases and poor-quality data. We streamline data processing and cleaning to allow for the rapid transition to usable data, improving the utility of data curated in these databases and furthering computing and modeling capabilities. \n",
    "\n",
    "While mineral identification and classification are obviously critical to the success of computational methodologies and machine learning (ML) applied to these large datasets, the question of how to best classify minerals from EPMA analyses comes to the fore. We approach this question by exploring and developing ML workflows, both supervised (classification algorithms) and unsupervised (dimensionality reduction and clustering). Unsupervised methods including autoencoders, a type of artificial neural network, present the opportunity to classify minerals with little a priori information. Autoencoders pair two neural networks with an encoder, compressing input data to a dimensionality-reduced latent representation, and a decoder, expanding latent representations to reconstruct the input and minimize loss. We present a novel autoencoder model aimed at meaningfully representing EPMA analyses of minerals in latent space, investigating the relationships between mineral phases, and performing classifications of these minerals. The model is trained with newly compiled datasets of twelve igneous mineral phases on thousands to tens of thousands of analyses per phase â€“ across tectonic settings to train these ML models. The autoencoder is applied to datasets of mineral analyses from PetDB, LEPR, and GEOROC to evaluate model performance and show significant improvements in mineral phase segregation and classification, critical to rigorous dataset quality control and future integration into data processing routines. \n",
    "\n",
    "[1] Lehnert, K. A., et al., 2022, IEDA2: Evolving EarthChem, LEPR/TraceDs, and SESAR into a Next Generation Data Infrastructure for Data-Driven Research Paradigms in Geochemistry, Petrology, and Volcanology, in 2022 Goldschmidt Conference.\n",
    "\n",
    "[2] Gale, A., et al., The mean composition of ocean ridge basalts. Geochemistry, Geophysics, Geosystems 14, 489-518 (2013).\n",
    "\n",
    "[3] Petrelli, M., et al., Machine learning thermobarometry: Application to clinopyroxene-bearing magmas. JGR: Solid Earth 125, e2020JB020130 (2020).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Accessing GEOROC mineral data with simple coding. \n",
    "\n",
    "### What am I looking at here? ###\n",
    "This is a Jupyter Notebook, a document in a web browser that you can edit, generate text, and run code (typically Python). In this particular case, to help the code run smoothly, we are doing the processing in the cloud using a tool called Google Colab. This means that you should be able to access all of the packages required and execute the code independent of the details of the computer that you are using locally - all you need is access to an internet connection and a web browser.\n",
    "\n",
    "\n",
    "### Online Big Data - Mineral compositions ###\n",
    "A key feature of modern earth and environmental sciences is that huge observational, experimental and thermodynamic datasets are now available. The IEDA2 data infrastructures hosts observational datasets with EarthChem and experimental and thermodynamic datasets with LEPR/TraceDs (Library of Experimental Phase Relations/Trace element Distribution experimental database). The GEOROC databases similarly hosts large datasets of petrologic data. Tools like Python allow for increased interaction with these datasets. In this practical we will look at a GEOROC dataset of electron microprobe analyses of minerals, which you can find on [GEOROC](https://doi.org/10.25625/SGFTFN). I take a subset of the full 856k dataset (20%) to make the data a bit more tractable. You can click on the links to understand the data sources. \n",
    "\n",
    "We focus on igneous minerals for this study, and thus we limit the mineral analyses to: \n",
    "\n",
    "- Amphibole\n",
    "- Apatite\n",
    "- Biotite\n",
    "- Clinopyroxene\n",
    "- Garnet\n",
    "- Ilmenite\n",
    "- K-Feldspar\n",
    "- Magnetite\n",
    "- Muscovite\n",
    "- Olivine \n",
    "- Orthopyroxene\n",
    "- Plagioclase\n",
    "- Quartz\n",
    "- Rutile\n",
    "- Spinel \n",
    "- Tourmaline \n",
    "- Zircon \n",
    "\n",
    "### NumPy for simple maths, Pandas for data-tables ###\n",
    "We will explore simple chemical relationships in the data using [numpy](https://numpy.org/) to perform simple mathematical calculations and using [pandas](https://pandas.pydata.org/) to read in data. We will use [matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/index.html) to plot. \n",
    "\n",
    "I'll put a couple of cells of code in below, which you should run, in order to import the correct packages and bathymetry data for use in the practical. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python packages for math, data, and plotting. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'size': 14})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Analyze the data. \n",
    "\n",
    "##### 1. Open the file you have just downloaded in Excel. Notice the huge amount of data! This is only a subset of the mineral analyses available on GEOROC. Petrologists have definitely been busy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets here with the Pandas package. We are storing the data as a dataframe, which is a 2D labeled data structure, like a 2D array or table with rows and columns. \n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/sarahshi/earthchem-teaching/main/data/GEOROC_subset.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset by calling the first 5 rows of data. What information is available?\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can print all column names to understand what is available by calling: \n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access particular columns of data by referencing them as follows: \n",
    "\n",
    "df['SiO2']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the presence of NaN (Not a Number) values. These are simply blank values in the Excel file. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Looking at df.head() gives us an indication of the columns present, including the one called 'Mineral', indicating the published mineral class. Let's further understand and visualize the data for each mineral class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can print the information stored in the 'Mineral' column, by calling: \n",
    "\n",
    "df['Mineral']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only see a few of all available mineral classes, but we can also display all the unique values within the column, by calling: \n",
    "\n",
    "df['Mineral'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we only want to look at the olivine data? We can use Python to subselect a portion of the data as follows: \n",
    "\n",
    "ol_df = df[df['Mineral'] == 'Olivine']\n",
    "\n",
    "ol_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot up these oxide distributions with a violin plot. \n",
    "\n",
    "oxides = ['SiO2', 'TiO2', 'Al2O3', 'FeOt', 'MnO', 'MgO', 'CaO', 'Na2O', 'K2O', 'Cr2O3']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.violinplot(ol_df[oxides].fillna(0), positions = np.linspace(0, 9, 10), showmeans = True, showextrema= False)\n",
    "ax.set_title('Olivine')\n",
    "ax.set_xlabel('Oxide')\n",
    "ax.set_ylabel('Weight Percentage')\n",
    "ax.set_xticks(np.linspace(0, 9, 10))\n",
    "ax.set_xticklabels(oxides, rotation = 45, fontsize = 15)\n",
    "ax.set_ylim([-5, 105])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Olivine contains primarily $SiO_2$, $FeO$, and $MgO$ as expected. This is great to visualize, but how do we analyze the entire dataset at the same time? What if I want to automate making violin plots for every mineral, instead of subsetting and creating a different figure each time? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = df['Mineral'].unique()\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize=(25, 15))\n",
    "ax = ax.flatten()\n",
    "for i in range(len(phase)): \n",
    "    if (df['Mineral'] == phase[i]).sum() > 0:\n",
    "        ax[i].violinplot(df[df['Mineral']==phase[i]][oxides].fillna(0), positions = np.linspace(0, 9, 10), showmeans = True, showextrema= False)\n",
    "        ax[i].set_title(phase[i])\n",
    "        ax[i].set_xticks(np.linspace(0, 9, 10))\n",
    "        ax[i].set_xticklabels(oxides, rotation = 45, fontsize = 15)\n",
    "        ax[i].set_ylim([-5, 105])\n",
    "\n",
    "fig.supylabel('Weight Percentage')\n",
    "fig.supxlabel('Oxide')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Model the data. \n",
    "\n",
    "Our goal is to classify minerals from the geochemistry. We can take a twofold approach: \n",
    "\n",
    "- Supervised: We assume prior knowledge of the mineral phase label. We see how algorithms can learn to classify things properly. \n",
    "- Unsupervised: We assume no prior knowledge of the mineral phase label. We see what patterns come out of the data. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Supervised Learning with Gaussian Discriminant Analysis\n",
    "\n",
    "We can appreciate that each mineral has distinct oxide composition distributions, usually normally distributed (potentially with long tails). The two minerals that are the most chemically similar are amphibole and clinopyroxene. The geochemical similarity between amphibole and clinopyroxene is well known, often leading petrologists to mistake the two minerals. \n",
    "\n",
    "[Gaussian Discriminant Analysis (GDA)](https://www.eecs189.org/static/notes/n18.pdf) is one way in which multivariate Gaussian distributions of features can be modeled, assuming uniqueness. The link contains some excellent information on the math behind GDA. Let's apply GDA to this dataset! We will do this by hand rather than using a Python package, to better understand the methodology. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pull a portion to serve as our training dataset -- what the model is calibrated upon. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, testing = train_test_split(df, train_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "df_train\n",
    "\n",
    "# Normally, we would perform a closer analysis of the data in the training dataset, but this module is more about presenting this methodology rather than about the specifics of these data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to analyze the mean and covariance matrices of each mineral class. To do so, let's define a function: \n",
    "\n",
    "def mean_cov(df):\n",
    "    oxides = ['SiO2', 'TiO2', 'Al2O3', 'FeOt', 'MnO', 'MgO', 'CaO', 'Na2O', 'K2O', 'Cr2O3']\n",
    "    data = df[oxides].values\n",
    "\n",
    "    # Calculate mean and covariance matrix\n",
    "    mean = np.mean(data, axis=0)\n",
    "    cov = np.cov(data, rowvar=False)\n",
    "\n",
    "    return mean, cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean and covariance. The mean_cov function calculates the mean and covariance matrix for a given subset of the dataset, which represents the feature statistics for each class.\n",
    "\n",
    "amp_mean, amp_cov = mean_cov(df_train[df_train.Mineral=='Amphibole'].fillna(0))\n",
    "ap_mean, ap_cov = mean_cov(df_train[df_train.Mineral=='Apatite'].fillna(0))\n",
    "bt_mean, bt_cov = mean_cov(df_train[df_train.Mineral=='Biotite'].fillna(0))\n",
    "cpx_mean, cpx_cov = mean_cov(df_train[df_train.Mineral=='Clinopyroxene'].fillna(0))\n",
    "gt_mean, gt_cov = mean_cov(df_train[df_train.Mineral=='Garnet'].fillna(0))\n",
    "il_mean, il_cov = mean_cov(df_train[df_train.Mineral=='Ilmenite'].fillna(0))\n",
    "ksp_mean, ksp_cov = mean_cov(df_train[df_train.Mineral=='KFeldspar'].fillna(0))\n",
    "ms_mean, ms_cov = mean_cov(df_train[df_train.Mineral=='Magnetite'].fillna(0))\n",
    "ol_mean, ol_cov = mean_cov(df_train[df_train.Mineral=='Olivine'].fillna(0))\n",
    "opx_mean, opx_cov = mean_cov(df_train[df_train.Mineral=='Orthopyroxene'].fillna(0))\n",
    "plag_mean, plag_cov = mean_cov(df_train[df_train.Mineral=='Plagioclase'].fillna(0))\n",
    "qtz_mean, qtz_cov = mean_cov(df_train[df_train.Mineral=='Quartz'].fillna(0))\n",
    "sp_mean, sp_cov = mean_cov(df_train[df_train.Mineral=='Spinel'].fillna(0))\n",
    "zr_mean, zr_cov = mean_cov(df_train[df_train.Mineral=='Zircon'].fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multivariate normal distributions: The multivariate_normal function is used to create a multivariate normal distribution for each class. \n",
    "# The mean and covariance matrix obtained in the previous step are used as parameters for these distributions.\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "amp_rv = multivariate_normal(amp_mean, amp_cov, allow_singular=True)\n",
    "ap_rv = multivariate_normal(ap_mean, ap_cov, allow_singular=True)\n",
    "bt_rv = multivariate_normal(bt_mean, bt_cov, allow_singular=True)\n",
    "cpx_rv = multivariate_normal(cpx_mean, cpx_cov, allow_singular=True)\n",
    "gt_rv = multivariate_normal(gt_mean, gt_cov, allow_singular=True)\n",
    "il_rv = multivariate_normal(il_mean, il_cov, allow_singular=True)\n",
    "ksp_rv = multivariate_normal(ksp_mean, ksp_cov, allow_singular=True)\n",
    "ms_rv = multivariate_normal(ms_mean, ms_cov, allow_singular=True)\n",
    "ol_rv = multivariate_normal(ol_mean, ol_cov, allow_singular=True)\n",
    "opx_rv = multivariate_normal(opx_mean, opx_cov, allow_singular=True)\n",
    "plag_rv = multivariate_normal(plag_mean, plag_cov, allow_singular=True)\n",
    "qtz_rv = multivariate_normal(qtz_mean, qtz_cov, allow_singular=True)\n",
    "sp_rv = multivariate_normal(sp_mean, sp_cov, allow_singular=True)\n",
    "zr_rv = multivariate_normal(zr_mean, zr_cov, allow_singular=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the best fit mineral: The class with the highest probability is selected as the predicted class for the data instance.\n",
    "\n",
    "# Store all the random variables in a dictionary for easier access\n",
    "rv_dict = {'Amphibole': amp_rv, 'Apatite': ap_rv, 'Biotite': bt_rv, 'Clinopyroxene': cpx_rv,\n",
    "           'Garnet': gt_rv, 'Ilmenite': il_rv, 'KFeldspar': ksp_rv, 'Magnetite': ms_rv,\n",
    "           'Olivine': ol_rv, 'Orthopyroxene': opx_rv, 'Plagioclase': plag_rv, 'Quartz': qtz_rv,\n",
    "           'Spinel': sp_rv, 'Zircon': zr_rv}\n",
    "\n",
    "# Define a function that will be applied to each row\n",
    "def get_best_fit_mineral(row):\n",
    "    # Calculate the PDF for each distribution and store the results in a dictionary\n",
    "    probs = {mineral: rv.pdf(row) for mineral, rv in rv_dict.items()}\n",
    "    \n",
    "    # Find the mineral with the highest probability\n",
    "    best_fit_mineral = max(probs, key=probs.get)\n",
    "\n",
    "    return best_fit_mineral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now want to apply this function to a test dataset. We pull some GEOROC data from the Cascades to perform this test. \n",
    "\n",
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/sarahshi/earthchem-teaching/main/CpxAmp_April23.csv\")\n",
    "\n",
    "# Use the `apply` method to apply the function to each row\n",
    "\n",
    "df_test['Best-Fit Mineral'] = df_test[oxides].fillna(0).apply(get_best_fit_mineral, axis=1)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check which values in the dataframe have published and predicted classifications agreeing vs. disagreeing. \n",
    "\n",
    "true = df_test[df_test['Mineral']==df_test['Best-Fit Mineral']]\n",
    "false = df_test[df_test['Mineral']!=df_test['Best-Fit Mineral']]\n",
    "\n",
    "print(str(len(true)) + ' classifications agree and ' + str(len(false)) + ' classifications disagree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can focus on minerals with common misclassifications -- in this case, clinopyroxene and amphibole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pubcpx_predcpx = true[(true['Mineral']=='Clinopyroxene') & (true['Best-Fit Mineral']=='Clinopyroxene')]\n",
    "\n",
    "pubcpx_predamp = false[(false['Mineral']=='Clinopyroxene') & (false['Best-Fit Mineral']=='Amphibole')]\n",
    "\n",
    "pubcpx_predamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pubamp_predamp = true[(true['Mineral']=='Amphibole') & (true['Best-Fit Mineral']=='Amphibole')]\n",
    "\n",
    "pubamp_predcpx = false[(false['Mineral']=='Amphibole') & (false['Best-Fit Mineral']=='Clinopyroxene')]\n",
    "\n",
    "pubamp_predcpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(pubcpx_predcpx['SiO2'], pubcpx_predcpx['Na2O'], color='tab:red', linewidth=0.2, ec='k', alpha=0.7, label='Pub:Cpx, GDA:Cpx')\n",
    "plt.scatter(pubamp_predamp['SiO2'], pubamp_predamp['Na2O'], color='tab:blue', linewidth=0.2, ec='k', alpha=0.7, label='Pub:Amp, GDA:Amp')\n",
    "\n",
    "plt.scatter(pubcpx_predamp['SiO2'], pubcpx_predamp['Na2O'], color='cyan', marker='d', s=60, linewidth=0.2, ec='k', label='Pub:Cpx, GDA:Amp')\n",
    "plt.scatter(pubamp_predcpx['SiO2'], pubamp_predcpx['Na2O'], color='yellow', marker='d', s=60, linewidth=0.2, ec='k', label='Pub:Amp, GDA:Cpx')\n",
    "\n",
    "plt.xlim([35, 60])\n",
    "plt.ylim([-0.1, 4.1])\n",
    "plt.xlabel('SiO2 (wt.%)')\n",
    "plt.ylabel('Na2O (wt.%)')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. How do predictions from GD compare to predictions from the neural network of the MIN-ML talk? See the results in the following figure:\n",
    "\n",
    "![minml_class](https://raw.githubusercontent.com/sarahshi/earthchem-teaching/main/figures/minml_class.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Unsupervised Learning with PCA\n",
    "\n",
    "Principal Components Analysis (PCA) is a linear transformation that resolves high dimensionality data and constructs principle components, or lower dimensionality representations of interrelated data. PCA constructs a covariance (and sometimes, the correlation) matrix of data and solves this eigenvector/eigenvalue problem to determine the matrix eigenvectors. The principle components, or the eigenvectors corresponding to the largest eigenvalues, thus identify the directions along which the variation in data is maximized in n-dimensional space.\n",
    "\n",
    "We can apply methods like PCA to glean what patterns exist within the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "oxides = ['SiO2', 'TiO2', 'Al2O3', 'FeOt', 'MnO', 'MgO', 'CaO', 'Na2O', 'K2O', 'Cr2O3']\n",
    "label = ['Mineral']\n",
    "\n",
    "min = df_train[label]\n",
    "wt = df_train[oxides].fillna(0).to_numpy()\n",
    "# Here, we apply a StandardScaler or z-score normalization to ensure that the oxides have similar numeric ranges. \n",
    "wt_scale = StandardScaler().fit_transform(wt)\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "pca_arr = pca.fit_transform(wt_scale)\n",
    "\n",
    "print(str(round(pca.explained_variance_ratio_.sum()*100, 2)) + '% of the variability in data is explained by 8 principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot up our PCA results for each mineral class. This code plots the first three principal components and automates the plotting process.  \n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as mcm\n",
    "\n",
    "phase = df['Mineral'].unique()\n",
    "phasez = range(1,len(phase))\n",
    "\n",
    "tab = plt.get_cmap('tab20')\n",
    "cNorm  = mcolors.Normalize(vmin=0, vmax=len(phase))\n",
    "scalarMap = mcm.ScalarMappable(norm=cNorm, cmap=tab)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (21, 7))\n",
    "ax = ax.flatten()\n",
    "# My feature_normalisation function has the same function as normalization from sklearn.preprocessing\n",
    "for i in range(len(phase)):\n",
    "    indx = min['Mineral'] == phase[i]\n",
    "    ax[0].scatter(pca_arr[indx][:, 0], pca_arr[indx][:, 1], s=15, color=scalarMap.to_rgba(i), lw=0.1, ec='k', alpha=0.75, label=phase[i])\n",
    "    ax[1].scatter(pca_arr[indx][:, 0], pca_arr[indx][:, 2], s=15, color=scalarMap.to_rgba(i), lw=0.1, ec='k', alpha=0.75, label=phase[i])\n",
    "    ax[2].scatter(pca_arr[indx][:, 1], pca_arr[indx][:, 2], s=15, color=scalarMap.to_rgba(i), lw=0.1, ec='k', alpha=0.75, label=phase[i])\n",
    "ax[0].legend(prop={'size': 8})\n",
    "ax[0].set_title('Normalization wt% - PCA')\n",
    "ax[0].set_xlabel('PC1')\n",
    "ax[0].set_ylabel('PC2')\n",
    "\n",
    "ax[1].legend(prop={'size': 8})\n",
    "ax[1].set_title('Normalization wt% - PCA')\n",
    "ax[1].set_xlabel('PC1')\n",
    "ax[1].set_ylabel('PC3')\n",
    "\n",
    "ax[2].legend(prop={'size': 8})\n",
    "ax[2].set_title('Normalization wt% - PCA')\n",
    "ax[2].set_xlabel('PC2')\n",
    "ax[2].set_ylabel('PC3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. How do predictions from PCA compare to predictions from the autoencoder of the MIN-ML talk? See the results in the following figure:\n",
    "\n",
    "![minml_autoencoder](https://raw.githubusercontent.com/sarahshi/earthchem-teaching/main/figures/minml_autoencoder.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geoinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e91381c0b7a2c44de84c4a9897039f757f22e48c5134c211a2030ac3c5236d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
